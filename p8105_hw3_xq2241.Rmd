---
title: "p8105_hw3_xq2241"
author: "Xinghao Qiao"
date: 2024-10-12
output: github_document
---

# question 1
```{r setup}
#import data
library(p8105.datasets)
library(dplyr)
library(lubridate) 
library(ggplot2)
library(gridExtra)
library(tidyr)
data("ny_noaa")
dim(ny_noaa)
str(ny_noaa)

# Calculate the frequency of missing data for each variable
missing<-ny_noaa |>
  summarize(across(everything(), ~sum(is.na(.)) )) |>
  pivot_longer(everything(), names_to = "variable", values_to = "freq_missing")

print(missing)


```
The raw dataset have 2595176 observation, with 7 variabvles; id (chr),date (date),prcp(int),snow (int),snwd(int),tmax(chr) and tmin (chr). And in the dataset, id and date don't have misssing value. Prcp has 145838 missing value, snow has 381221 missing value, snwd has 591786 missing value, tmax has 1134358 missing value and tmin has 1134420 missing value.

First, let's do some data cleaning.
```{r}
#Create separate variables for year, month, and day
ny_noaa <- ny_noaa |>
  mutate(year = year(date), month = month(date), day = day(date))

```
Then, we ensure observations for temperature, precipitation, and snowfall are given in reasonable units.
```{r}
ny_noaa <- ny_noaa |>
  mutate(
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin),
    month = as.numeric(month),
    prcp = prcp / 10,  # converting from tenths of mm to mm
    snow = snow,       
    tmax = tmax / 10,  # converting to degrees C
    tmin = tmin / 10   # converting to degrees C
  )

```
For the most commonly observed snowfall values, we have,
```{r}
snowfall <- ny_noaa |>
  filter(!is.na(snow)) |>
  group_by(snow) |>
  summarize(count = n()) |>
  arrange(desc(count))

# View the most common snowfall values
head(snowfall)

```
From the output,we have the most commonly observed values for snowfall is 0 mm.

Now, we draw the Two-panel plot for the average max temperature in January and in July.
```{r}
average_tmax <- ny_noaa |>
  filter(month %in% c(1, 7), !is.na(tmax)) |>
  group_by(id, year, month) |>
  summarize(mean_tmax = mean(tmax, na.rm = TRUE), .groups = "drop")

# Create the two-panel plot
ggplot(average_tmax, aes(x = year, y = mean_tmax, color = id)) +
  geom_point() +
  facet_wrap(~month, ncol = 1, scales = "free_y", labeller = as_labeller(c(`1` = "January", `7` = "July"))) +
  labs(
    title = "Average Max Temperature in January and July across Years",
    x = "Year",
    y = "Average Max Temperature (°C)",
    color = "Station ID"
  ) +
  theme_minimal()+ theme(legend.position = "none") 
```
From the plot, we have observed that the average maximum temperature shows seasonality,the average maximum temperature in January mainly distributed between -10°C and 5°C across years and in July the temperature mainly distributed between 25°C to 35°C.And there is no clear long-term trend from the plot over the years between 1980 and 2010. Also, there are some outliers in the plot. For instance, there are points lower than surrounding points in January of 1982 and in July of 1988.

Now, we will make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option); and (ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.
```{r}
#panel 1 :tmax vs tmin for the full dataset 
panel1 <- ggplot(ny_noaa, aes(x = tmin, y = tmax)) +
  geom_hex(bins = 50) +  
  scale_fill_viridis_c() + 
  labs(
    x = "Min Temperature (°C)",
    y = "Max Temperature (°C)",
    fill = "Count"
  ) +
  theme_minimal()
# Panel 2: Distribution of snowfall values greater than 0 and less than 100, by year
panel2<- ggplot(ny_noaa |> filter(snow > 0 & snow < 100), aes(x = snow, fill = as.factor(year))) +
  geom_density(alpha = 0.7) +  
  facet_wrap(~year, scales = "free_y") +
  labs(
    x = "Snowfall (mm)",
    y = "Density"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
# Arrange the two panels

grid.arrange(panel1, panel2, nrow = 2,heights = c(1, 2))

```


# question 2
First,let's import the dataset.

```{r}
library(readr)
accel <- read_csv("nhanes_accel.csv")
covar <- read_csv("nhanes_covar.csv",skip = 4)
```
Then, we will creat a new merged dataset.
```{r}
colnames(covar) <- c("SEQN", "sex", "age", "BMI", "education")
# Merge the data on SEQN
merged_data <- accel |>
  inner_join(covar, by = "SEQN") |>
  filter(age >= 21)  # Exclude participants under 21

# Convert sex and education to factors
merged_data <- merged_data |>
  mutate(
    sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female")),
    education = factor(education, levels = c(1, 2, 3), 
                       labels = c("Less than high school", "High school equivalent", "More than high school"))
  )
# Exclude participants with missing demographic data
cleaned_data <- merged_data |>
  filter(!is.na(sex), !is.na(age), !is.na(education),!is.na(BMI))

cleaned_data <- cleaned_data |>
  select(SEQN, sex, age, education, BMI, everything(), starts_with("min"))

# View the cleaned data
print(head(cleaned_data))

```
With the cleaned dataset, we can produce a reader-friendly table for the number of men and women in each education category and a visualization of the age distributions for men and women in each education category. 
```{r}
# Create a summary table 
summary <- cleaned_data |>
  group_by(sex, education) |>
  summarize(count = n()) |>
  spread(key = sex, value = count)  

# Rename columns 
colnames(summary) <- c("Education", "Number of Men", "Number of Women")
# Print the summary table
print(summary)

# Plot the age distribution by gender and education
ggplot(cleaned_data, aes(x = age, fill = sex)) +
  geom_histogram(binwidth = 5, position = "dodge", alpha = 0.7) +
  facet_wrap(~education) +
  labs(title = "Age Distribution by Gender and Education",
       x = "Age",
       y = "Count",
       fill = "Gender") +
  theme_minimal()
```
From the table, for those having education less than high school,27 people is men and 28 people is women;for those having high school education, 35 people is men and 23 people is women; for those having education more than high school, 56 people is men and 59 people is women.And from the histogram, the age distributions for men and women in less than high school education and high school education are very similar. However, in more than high school group, female has more people have more than high school education at young age.

Now, we can produce the next plot.

```{r}
#calculate  total activities 
cleaned_data$total_activity <- rowSums(select(cleaned_data, starts_with("min")), na.rm = TRUE)

#Create a scatter plot by different education level 
ggplot(cleaned_data, aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = 0.6) +  
  geom_smooth(method = "loess", se = FALSE) +  # Add a smooth trend line without confidence interval
  facet_wrap(~education) +  # Separate panels
  labs(
    title = "Total Daily Activity vs Age by Gender and Education Level",
    x = "Age",
    y = "Total Activity",
    color = "Gender"
  ) +
  theme_minimal()  
```
From the plot, there is a general downward trend in total daily activity as age increases in all education categories.In the less than high school group, younger men tend to be more active than women, but this difference narrows as age increases.In the high school equivalent group, women tend to be more active than men. And in the more than high school group, the differences between men and women seem to persist across age, with some fluctuation in activity levels in older participants.

Then, let's analyse the 24-hour activity time courses for each education level.
```{r}
# Reshape the accelerometer data into a long format
long_data <- cleaned_data %>%
  pivot_longer(cols = starts_with("min"), 
               names_to = "minute", 
               names_prefix = "min", 
               values_to = "MIMS") %>%
  mutate(minute = as.numeric(minute))  # Convert the variable to numeric
# Calculate the average activity by minute, education level, and gender
average_activity <- long_data %>%
  group_by(minute, education, sex) %>%
  summarize(mean_mims = mean(MIMS, na.rm = TRUE))

# Plot the 24-hour activity time course for each education level
ggplot(average_activity, aes(x = minute, y = mean_mims, color = sex)) +
  geom_line(linewidth = 1) +  # Line plot to show the 24-hour activity trend
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed",alpha = 0.2) +  # Add lines
  facet_wrap(~education) +  # Separate panels for each education level
  scale_x_continuous(breaks = seq(0, 1440, by = 240),  # 240 minutes is 4-hour intervals
                     labels = c("0", "4 AM", "8 AM", "Noon", "4 PM", "8 PM", "0")) +
  labs(
    title = "24-Hour Activity by Education Level and Gender",
    x = "Time of Day",
    y = "Mean MIMS (Activity Level)",
    color = "Gender"
  ) +
  theme_minimal()
```
From the plot,there is a clear increase in activity starting early in the morning (around 6 AM), which peaks in the late morning or early afternoon across all education levels. And in the "Less than high school" and "High school equivalent" groups, men tend to show slightly higher activity levels in the earlier parts of the day.However,in the "More than high school" group, women tend to be more active than men throughout the day.

# question 3
First,let's import the dataset.
```{r}
jan_2020 <- read_csv("citibike/Jan 2020 Citi.csv")
jan_2024 <- read_csv("citibike/Jan 2024 Citi.csv")
july_2020 <- read_csv("citibike/July 2020 Citi.csv")
july_2024 <- read_csv("citibike/July 2024 Citi.csv")

glimpse(july_2024)
glimpse(jan_2020)
glimpse(july_2020)
glimpse(jan_2024)
```
Now,we can merge the dataset together.
```{r}
# Add year and month columns to each dataset
july_2024 <- july_2024 |>
  mutate(year = 2024, month = "July")

jan_2020 <- jan_2020 |>
  mutate(year = 2020, month = "January")

july_2020 <- july_2020|>
  mutate(year = 2020, month = "July")

jan_2024<- jan_2024 |>
  mutate(year = 2024, month = "January")

# Combine the datasets into one
combined_data <- bind_rows(july_2024, jan_2020, july_2020, jan_2024)

colnames(combined_data)

```
Now,we produce a reader-friendly table showing the total number of rides in each combination of year and month separating casual riders and Citi Bike members. 
```{r}
ride_summary <- combined_data |>
  group_by(year, month, member_casual) |>
  summarize(total_rides = n(), .groups = 'drop')

# Step 2: Create a reader-friendly table
library(knitr)
kable(ride_summary, caption = "Total Number of Rides by Year, Month, and User Type")
```
From the table, there were 984 casual riders and 11436 citi member riderss in Jan. 2020,there were 5637 casual riders and 15411 citi member riderss in Jul. 2020,there were 2108 casual riders and 16753 citi member riderss in Jan. 2024,there were 10894 casual riders and 36262 citi member riders in Jul. 2024. 

Now, we will make a table showing the 5 most popular starting stations for July 2024.
```{r}
july_2024_stations <- combined_data |>
  filter(year == 2024 & month == "July")

# Group by the starting station and count the number of rides
popular_stations <- july_2024_stations |>
  group_by(start_station_name) |>
  summarize(total_rides = n(), .groups = 'drop') |>
  arrange(desc(total_rides))  # Sort by total rides in descending order
#top 5
top_5_stations <- head(popular_stations, 5)
#table
kable(top_5_stations, caption = "Top 5 Most Popular Starting Stations in July 2024")
```
So, the top 5 stations are 'Pier 61 at Chelsea Piers','University Pl & E 14 St','W 21 St & 6 Ave','West St & Chambers St','W 31 St & 7 Ave'.

Then, making a plot to investigate the effects of day of the week, month, and year on median ride duration.
```{r}
median_duration <- combined_data |>
  group_by(year, month, weekdays) |>
  summarize(median_duration = median(duration, na.rm = TRUE), .groups = 'drop')

# Step 2: Create a plot using ggplot2
library(ggplot2)

ggplot(median_duration, aes(x = weekdays, y = median_duration, fill = weekdays)) +
  geom_bar(stat = "identity", position = "dodge") +  # Use bars to show median duration for each day
  facet_wrap(year ~ month) +  # by year and month
  labs(
    x = "Day of the Week",
    y = "Median Ride Duration (minutes)",
    fill = "Day"
  ) +
  theme_minimal() + theme(
    axis.text.x = element_text(angle = 90)  #Rotate the X-axis label 90 degree
  )
```
From the plot,July consistently shows higher median ride duration compared to January for both years (2020 and 2024).And weekends consistently show higher median ride duration compared to weekdays, especially in July. 

Finally,we will make a figure that shows the impact of month, membership status, and bike type on the distribution of ride duration. 
```{r}
data_2024 <- combined_data |>
  filter(year == 2024)

# create the plot showing the distribution of ride duration

ggplot(data_2024, aes(x = member_casual, y = duration, fill = rideable_type)) +
  geom_violin(trim = F, scale = "width") +  # Violin plot
  facet_wrap(~month) +
  scale_y_log10() + # Use log scale for ride duration due to skewness
  labs(
    title = "Impact of Month, Membership Status, and Bike Type on Ride Duration (2024)",
    x = "Membership Status",
    y = "Ride Duration (minutes)",
    fill = "Bike Type"
  ) +
  theme_minimal()
```
From the plot,electric bikes consistently show longer ride duration compared to classic bikes across both casual riders and members.For casual riders, electric bikes have a noticeably wider distribution of ride duration, so casual riders may be more likely to take longer trips on electric bikes.And the ride duration of citi member riders are shorter on both bike types compared to casual riders.

